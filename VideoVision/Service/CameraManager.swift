//
//  CameraManager.swift
//  VideoVision
//
//  Created by KimRin on 1/7/26.
// NSObjectì™€ Delegateì˜ ìƒê´€ê´€ê³„
//


import AVFoundation

class CameraManager: NSObject {
	private let captureSession = AVCaptureSession()
	
	private var simulationTimer: Timer?
	
	var session: AVCaptureSession {
		return self.captureSession
	}
	
	//ë¹„ë””ì˜¤ ì•„ì›ƒí’‹
	private let videoOutput = AVCaptureVideoDataOutput()
	// ë¹„ë””ì˜¤ í
	private let videoOutputQueue = DispatchQueue(label: "com.video.output")
	
	// ì•± ê¶Œí•œ í™•ì¸
	func checkPermission() {
		switch AVCaptureDevice.authorizationStatus(for: .video) {
		case .authorized:
			self.startSession()
		case .notDetermined:
			AVCaptureDevice.requestAccess(for: .video) { [weak self] granted in
				if granted {
					self?.startSession()
				}
				
			}
		case .denied, .restricted:
			// TODO: -  ì„¤ì •ìœ ë„ ì•Œë¦¼ ( ì„¤ì • ì•Œë¦¼ì°½ ë”¥ë§í¬ ìœ ë„ )
			print("Permission denied")
		@unknown default:
			break
		}
		
	}
	
	func startSession() {
#if targetEnvironment(simulator)
		print("ğŸ“± Simulator Mode: Starting Mock Camera...")
		self.startSimulation()
#else
		// ì‹¤ê¸°ê¸°ì¼ ë•Œ ê¸°ì¡´ ë¡œì§
		self.setupCamera()
		DispatchQueue.global(qos: .background).async {
			if !self.captureSession.isRunning {
				self.captureSession.startRunning()
			}
		}
#endif
	}
	
	private func startSimulation() {
		// 0.033ì´ˆ (ì•½ 30FPS)ë§ˆë‹¤ íƒ€ì´ë¨¸ ì‹¤í–‰
		self.simulationTimer = Timer.scheduledTimer(withTimeInterval: 0.033, repeats: true) { [weak self] _ in
			guard let self = self else { return }
			
			// 1. ê°€ì§œ ë°ì´í„° ìƒì„±
			guard let mockBuffer = MockDataGenerator.makeMockPixelBuffer() else { return }
			
			// 2. ì¤‘ìš”!! ìš°ë¦¬ê°€ ë§Œë“  'Serial Queue'ë¡œ ì‘ì—…ì„ ë³´ëƒ„ (ì‹¤ì œ ì¹´ë©”ë¼ ë™ì‘ í‰ë‚´)
			self.videoOutputQueue.async {
				// 3. ë¸ë¦¬ê²Œì´íŠ¸ ì§ì ‘ í˜¸ì¶œ (CMSampleBuffer ëŒ€ì‹  PixelBufferë¥¼ ë°”ë¡œ ì²˜ë¦¬í•˜ë„ë¡ ë¡œì§ ìˆ˜ì • í•„ìš”í•  ìˆ˜ ìˆìŒ)
				// í¸ì˜ìƒ ì—¬ê¸°ì„œ ë°”ë¡œ ì²˜ë¦¬ ë¡œì§ì„ í˜¸ì¶œí•˜ê±°ë‚˜, Mockìš© Delegate ë©”ì„œë“œë¥¼ ë§Œë“­ë‹ˆë‹¤.
				self.handleMockFrame(buffer: mockBuffer)
			}
		}
	}
	
	
	private func handleMockFrame(buffer: CVPixelBuffer) {
		// ì—¬ê¸°ì— ì•„ê¹Œ ì‘ì„±í•œ ì²˜ë¦¬ ë¡œì§(Lock -> Print -> Unlock)ì„ ë„£ìœ¼ì„¸ìš”.
		
		CVPixelBufferLockBaseAddress(buffer, .readOnly)
		let width = CVPixelBufferGetWidth(buffer)
		let height = CVPixelBufferGetHeight(buffer)
		print("ğŸ¤– Mock Frame: \(width)x\(height) | Thread: \(Thread.current)")
		CVPixelBufferUnlockBaseAddress(buffer, .readOnly)
	}
	
	func stopSession() {
		self.captureSession.stopRunning()
	}
	
	
	private func setupCamera() {
		
		self.captureSession.beginConfiguration()
		//í™”ì§ˆ
		self.captureSession.sessionPreset = .high
		//camera input setting
		if let videoDevice = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .front),
		   let videoInput = try? AVCaptureDeviceInput(device: videoDevice) {
			if self.captureSession.canAddInput(videoInput) {
				self.captureSession.addInput(videoInput)
			}
		}
		
		// mic input setting
		if let audioDevice = AVCaptureDevice.default(for: .audio),
		   let audioInput = try? AVCaptureDeviceInput(device: audioDevice) {
			if self.captureSession.canAddInput(audioInput) {
				self.captureSession.addInput(audioInput)
				print("mic connected")
			}
		}
		
		if self.captureSession.canAddOutput(videoOutput) {
			self.captureSession.addOutput(videoOutput)
			// TODO: -  ëŠ¦ê²Œ ë“¤ì–´ì˜¨ í”„ë ˆì„ì€ ë²„ë¦¬ê¸° (ì‹¤ì‹œê°„ ë°©ì†¡ì—ì„œëŠ” ì§€ì—°ì„ ì¤„ì´ëŠ” ê²Œ í™”ì§ˆë³´ë‹¤ ì¤‘ìš”) ì°¾ì•„ë³¼ê²ƒ
			videoOutput.alwaysDiscardsLateVideoFrames = true
			
			// TODO: - í”½ì…€ í¬ë§· ì„¤ì • (iOS í™”ë©´ ì¶œë ¥ ë° ì²˜ë¦¬ì— ê°€ì¥ ë§ì´ ì“°ì´ëŠ” BGRA í˜•ì‹) ë‚´ìš© ì„œì¹˜
			videoOutput.videoSettings = [
				kCVPixelBufferPixelFormatTypeKey as String: Int(kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange)
			]
			
			// TODO: - 	ë¸ë¦¬ê²Œì´íŠ¸ ì—°ê²° (ë°ì´í„°ë¥¼ ë°›ì„ ëŒ€ë¦¬ìëŠ” self, ì²˜ë¦¬ëŠ” videoOutputQueueì—ì„œ) ì°¾ì•„ë³¼ê²ƒ
			videoOutput.setSampleBufferDelegate(self, queue: videoOutputQueue)
			
			
		}
		if let connection = videoOutput.connection(with: .video) {
			
			// ë°©í–¥(Rotation)
			if #available(iOS 17.0, *) {
				if connection.isVideoRotationAngleSupported(90) {
					connection.videoRotationAngle = 90
				}
			} else {
				// iOS 16 ì´í•˜ ë°©í–¥(Enum)ìœ¼ë¡œ ì„¤ì •
				if connection.isVideoOrientationSupported {
					connection.videoOrientation = .portrait
				}
			}
			
		}
		self.captureSession.commitConfiguration()
	}
	
	func switchCamera() {
		self.captureSession.beginConfiguration()
		
		guard let currentInput = self.captureSession.inputs.first(where: { ($0 as? AVCaptureDeviceInput)?.device.hasMediaType(.video) ?? false }) as? AVCaptureDeviceInput else {
			self.captureSession.commitConfiguration()
			return
		}
		
		let newPosition: AVCaptureDevice.Position = (currentInput.device.position == .front) ? .back : .front
		
		guard let newDevice = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: newPosition),
			  let newInput = try? AVCaptureDeviceInput(device: newDevice) else {
			self.captureSession.commitConfiguration()
			return
		}
		
		self.captureSession.removeInput(currentInput)
		
		// Output ì—°ê²°ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ë˜ë¯€ë¡œ Inputë§Œ ê°ˆì•„ë¼ìš°ë©´ ë¨
		if self.captureSession.canAddInput(newInput) {
			self.captureSession.addInput(newInput)
		} else {
			self.captureSession.addInput(currentInput)
		}
		
		// í™”ë©´ ì „í™˜ ì‹œ ì˜¤ë¦¬ì—”í…Œì´ì…˜ì´ë‚˜ ë¯¸ëŸ¬ë§ ì´ìŠˆê°€ ìƒê¸¸ ìˆ˜ ìˆëŠ”ë°, ê·¸ê±´ ì¶”í›„ ì²˜ë¦¬
		self.captureSession.commitConfiguration()
	}
	
	
	func setupSession() {
		
	}
	
	
}


extension CameraManager: AVCaptureVideoDataOutputSampleBufferDelegate {
	func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
		print("test")
	}
}
